==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 38,841,827
Non-trainable parameters: 0
Total parameters: 38,841,827
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.664927536231884
0.7970505617977529
[[  12  566]
 [  12 1135]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 21s - loss: 5.5638 - acc: 0.6709 - val_loss: 5.0991 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_132544.hdf5
Epoch 2/30
 - 18s - loss: 5.3847 - acc: 0.6712 - val_loss: 5.0052 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 18s - loss: 5.3313 - acc: 0.6712 - val_loss: 4.9776 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 19s - loss: 5.3142 - acc: 0.6712 - val_loss: 4.9677 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 19s - loss: 5.3077 - acc: 0.6712 - val_loss: 4.9636 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 19s - loss: 5.3048 - acc: 0.6712 - val_loss: 4.9616 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 19s - loss: 5.3033 - acc: 0.6712 - val_loss: 4.9605 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 19s - loss: 5.3024 - acc: 0.6712 - val_loss: 4.9598 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 19s - loss: 2.5116 - acc: 0.6270 - val_loss: 0.6619 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 19s - loss: 0.6591 - acc: 0.6601 - val_loss: 0.6914 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 19s - loss: 0.6503 - acc: 0.6663 - val_loss: 0.6319 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 19s - loss: 0.6477 - acc: 0.6712 - val_loss: 0.6267 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 19s - loss: 0.6541 - acc: 0.6712 - val_loss: 0.6508 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 19s - loss: 0.6622 - acc: 0.6712 - val_loss: 0.6508 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 19s - loss: 0.6614 - acc: 0.6712 - val_loss: 0.6346 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 19s - loss: 0.6774 - acc: 0.6601 - val_loss: 0.6537 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 19s - loss: 0.6748 - acc: 0.6712 - val_loss: 0.6674 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 19s - loss: 0.6735 - acc: 0.6712 - val_loss: 0.6705 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 19s - loss: 0.6855 - acc: 0.6534 - val_loss: 0.6557 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 19s - loss: 0.6730 - acc: 0.6712 - val_loss: 0.6443 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 19s - loss: 0.6635 - acc: 0.6712 - val_loss: 0.6588 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 19s - loss: 0.6704 - acc: 0.6712 - val_loss: 0.6401 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 19s - loss: 0.6607 - acc: 0.6712 - val_loss: 0.6459 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 19s - loss: 0.6677 - acc: 0.6620 - val_loss: 0.6417 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 19s - loss: 0.6533 - acc: 0.6712 - val_loss: 0.6416 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 19s - loss: 0.6463 - acc: 0.7141 - val_loss: 0.7088 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 19s - loss: 0.6007 - acc: 0.8344 - val_loss: 0.6946 - val_acc: 0.7328
val_acc: 0.7328
val_f1: 0.8348
val_conf_mat:
[[ 47 204]
 [ 14 551]]

Epoch 00027: val_acc improved from 0.69240 to 0.73284, saving model to ../checkpoints/he_mpcnn/cp_20180622_132544.hdf5
Epoch 28/30
 - 19s - loss: 0.4961 - acc: 0.9037 - val_loss: 0.7237 - val_acc: 0.7451
val_acc: 0.7451
val_f1: 0.8123
val_conf_mat:
[[158  93]
 [115 450]]

Epoch 00028: val_acc improved from 0.73284 to 0.74510, saving model to ../checkpoints/he_mpcnn/cp_20180622_132544.hdf5
Epoch 29/30
 - 19s - loss: 0.4435 - acc: 0.9196 - val_loss: 0.7188 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8282
val_conf_mat:
[[151 100]
 [ 95 470]]

Epoch 00029: val_acc improved from 0.74510 to 0.76103, saving model to ../checkpoints/he_mpcnn/cp_20180622_132544.hdf5
Epoch 30/30
 - 19s - loss: 0.3979 - acc: 0.9399 - val_loss: 0.6632 - val_acc: 0.7684
val_acc: 0.7684
val_f1: 0.8394
val_conf_mat:
[[133 118]
 [ 71 494]]

Epoch 00030: val_acc improved from 0.76103 to 0.76838, saving model to ../checkpoints/he_mpcnn/cp_20180622_132544.hdf5
Done!


======================
Last epoch predictions
======================
acc: 0.7275362318840579
f1:  0.8103309120258273
confusion matrix
[[ 251  327]
 [ 143 1004]]
======================
Best epoch predictions
======================
acc: 0.7275362318840579
f1:  0.8103309120258273
confusion matrix
[[ 251  327]
 [ 143 1004]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 325


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 325), (2, 325), (3, 325), (None, 325)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 22,907,227
Non-trainable parameters: 0
Total parameters: 22,907,227
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.43768115942028984
0.46349557522123896
[[336 242]
 [728 419]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 14s - loss: 5.4831 - acc: 0.6687 - val_loss: 5.0864 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 2/30
 - 11s - loss: 5.3858 - acc: 0.6712 - val_loss: 5.0131 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 11s - loss: 5.3400 - acc: 0.6712 - val_loss: 4.9860 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 12s - loss: 5.3217 - acc: 0.6712 - val_loss: 4.9741 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 12s - loss: 5.3132 - acc: 0.6712 - val_loss: 4.9683 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 12s - loss: 5.3088 - acc: 0.6712 - val_loss: 4.9651 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 12s - loss: 5.3063 - acc: 0.6712 - val_loss: 4.9631 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 12s - loss: 5.3048 - acc: 0.6712 - val_loss: 4.9619 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 12s - loss: 5.3037 - acc: 0.6712 - val_loss: 4.9610 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 12s - loss: 5.3030 - acc: 0.6712 - val_loss: 4.9604 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 12s - loss: 5.3025 - acc: 0.6712 - val_loss: 4.9599 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 12s - loss: 5.3021 - acc: 0.6712 - val_loss: 4.9596 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 12s - loss: 5.3017 - acc: 0.6712 - val_loss: 4.9593 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 12s - loss: 5.3015 - acc: 0.6712 - val_loss: 4.9591 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 12s - loss: 2.3416 - acc: 0.6393 - val_loss: 0.6629 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 12s - loss: 0.6707 - acc: 0.6577 - val_loss: 0.6382 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 12s - loss: 0.6623 - acc: 0.6712 - val_loss: 0.6406 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 11s - loss: 0.6614 - acc: 0.6721 - val_loss: 0.6632 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 12s - loss: 0.6535 - acc: 0.7077 - val_loss: 0.7046 - val_acc: 0.7157
val_acc: 0.7157
val_f1: 0.8281
val_conf_mat:
[[ 25 226]
 [  6 559]]

Epoch 00019: val_acc improved from 0.69240 to 0.71569, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 20/30
 - 11s - loss: 0.5769 - acc: 0.8233 - val_loss: 0.6754 - val_acc: 0.7316
val_acc: 0.7316
val_f1: 0.7872
val_conf_mat:
[[192  59]
 [160 405]]

Epoch 00020: val_acc improved from 0.71569 to 0.73162, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 21/30
 - 12s - loss: 0.4401 - acc: 0.9117 - val_loss: 0.6542 - val_acc: 0.7696
val_acc: 0.7696
val_f1: 0.8476
val_conf_mat:
[[105 146]
 [ 42 523]]

Epoch 00021: val_acc improved from 0.73162 to 0.76961, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 22/30
 - 11s - loss: 0.3727 - acc: 0.9457 - val_loss: 0.7453 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8203
val_conf_mat:
[[176  75]
 [120 445]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 12s - loss: 0.2454 - acc: 0.9745 - val_loss: 0.7483 - val_acc: 0.7672
val_acc: 0.7672
val_f1: 0.8509
val_conf_mat:
[[ 84 167]
 [ 23 542]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 12s - loss: 0.1819 - acc: 0.9868 - val_loss: 0.6598 - val_acc: 0.7819
val_acc: 0.7819
val_f1: 0.8430
val_conf_mat:
[[160  91]
 [ 87 478]]

Epoch 00024: val_acc improved from 0.76961 to 0.78186, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 25/30
 - 12s - loss: 0.1428 - acc: 0.9923 - val_loss: 0.7721 - val_acc: 0.7488
val_acc: 0.7488
val_f1: 0.8053
val_conf_mat:
[[187  64]
 [141 424]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 12s - loss: 0.1132 - acc: 0.9942 - val_loss: 0.8472 - val_acc: 0.7549
val_acc: 0.7549
val_f1: 0.8134
val_conf_mat:
[[180  71]
 [129 436]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 12s - loss: 0.0932 - acc: 0.9969 - val_loss: 0.8519 - val_acc: 0.7770
val_acc: 0.7770
val_f1: 0.8473
val_conf_mat:
[[129 122]
 [ 60 505]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 12s - loss: 0.0778 - acc: 0.9982 - val_loss: 0.9653 - val_acc: 0.7868
val_acc: 0.7868
val_f1: 0.8427
val_conf_mat:
[[176  75]
 [ 99 466]]

Epoch 00028: val_acc improved from 0.78186 to 0.78676, saving model to ../checkpoints/he_mpcnn/cp_20180622_133617.hdf5
Epoch 29/30
 - 11s - loss: 0.0573 - acc: 0.9985 - val_loss: 0.8910 - val_acc: 0.7770
val_acc: 0.7770
val_f1: 0.8375
val_conf_mat:
[[165  86]
 [ 96 469]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 12s - loss: 0.0524 - acc: 0.9982 - val_loss: 1.0507 - val_acc: 0.7243
val_acc: 0.7243
val_f1: 0.7788
val_conf_mat:
[[195  56]
 [169 396]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.7240579710144928
f1:  0.7709335899903755
confusion matrix
[[448 130]
 [346 801]]
======================
Best epoch predictions
======================
acc: 0.76
f1:  0.818739054290718
confusion matrix
[[376 202]
 [212 935]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
Final embeddings dim: 500


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 500), (2, 500), (3, 500), (None, 500)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 36,771,252
Non-trainable parameters: 0
Total parameters: 36,771,252
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.3356521739130435
0.0017421602787456446
[[ 578    0]
 [1146    1]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 19s - loss: 5.5734 - acc: 0.6693 - val_loss: 5.1338 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_134251.hdf5
Epoch 2/30
 - 17s - loss: 5.4144 - acc: 0.6712 - val_loss: 5.0294 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 18s - loss: 5.3511 - acc: 0.6712 - val_loss: 4.9936 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 18s - loss: 5.3276 - acc: 0.6712 - val_loss: 4.9788 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 18s - loss: 5.3173 - acc: 0.6712 - val_loss: 4.9718 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 18s - loss: 5.3121 - acc: 0.6712 - val_loss: 4.9680 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 18s - loss: 5.3090 - acc: 0.6712 - val_loss: 4.9656 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 18s - loss: 5.3071 - acc: 0.6712 - val_loss: 4.9640 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 17s - loss: 5.3057 - acc: 0.6712 - val_loss: 4.9628 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 18s - loss: 5.3047 - acc: 0.6712 - val_loss: 4.9619 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 18s - loss: 5.3039 - acc: 0.6712 - val_loss: 4.9613 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 18s - loss: 5.3033 - acc: 0.6712 - val_loss: 4.9607 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 17s - loss: 5.3028 - acc: 0.6712 - val_loss: 4.9603 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 18s - loss: 5.3024 - acc: 0.6712 - val_loss: 4.9599 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 18s - loss: 5.3020 - acc: 0.6712 - val_loss: 4.9596 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 18s - loss: 5.3018 - acc: 0.6712 - val_loss: 4.9594 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 18s - loss: 3.6243 - acc: 0.6282 - val_loss: 0.6462 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 18s - loss: 0.6604 - acc: 0.6663 - val_loss: 0.6528 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 18s - loss: 0.6516 - acc: 0.6620 - val_loss: 0.6389 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 18s - loss: 0.6524 - acc: 0.6712 - val_loss: 0.6236 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 18s - loss: 0.6508 - acc: 0.6638 - val_loss: 0.6316 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 18s - loss: 0.6464 - acc: 0.6632 - val_loss: 0.6250 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 18s - loss: 0.6667 - acc: 0.6712 - val_loss: 0.6458 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 18s - loss: 0.6657 - acc: 0.6709 - val_loss: 0.6669 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 18s - loss: 0.6705 - acc: 0.6733 - val_loss: 0.6569 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 18s - loss: 0.6396 - acc: 0.7500 - val_loss: 0.6938 - val_acc: 0.7414
val_acc: 0.7414
val_f1: 0.8345
val_conf_mat:
[[ 73 178]
 [ 33 532]]

Epoch 00026: val_acc improved from 0.69240 to 0.74142, saving model to ../checkpoints/he_mpcnn/cp_20180622_134251.hdf5
Epoch 27/30
 - 17s - loss: 0.5640 - acc: 0.8733 - val_loss: 0.7381 - val_acc: 0.7353
val_acc: 0.7353
val_f1: 0.8364
val_conf_mat:
[[ 48 203]
 [ 13 552]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 18s - loss: 0.4720 - acc: 0.9288 - val_loss: 0.7080 - val_acc: 0.7586
val_acc: 0.7586
val_f1: 0.8326
val_conf_mat:
[[129 122]
 [ 75 490]]

Epoch 00028: val_acc improved from 0.74142 to 0.75858, saving model to ../checkpoints/he_mpcnn/cp_20180622_134251.hdf5
Epoch 29/30
 - 18s - loss: 0.4504 - acc: 0.9202 - val_loss: 0.6884 - val_acc: 0.7500
val_acc: 0.7500
val_f1: 0.8159
val_conf_mat:
[[160  91]
 [113 452]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 18s - loss: 0.3546 - acc: 0.9583 - val_loss: 0.7562 - val_acc: 0.7598
val_acc: 0.7598
val_f1: 0.8199
val_conf_mat:
[[174  77]
 [119 446]]

Epoch 00030: val_acc improved from 0.75858 to 0.75980, saving model to ../checkpoints/he_mpcnn/cp_20180622_134251.hdf5
Done!


======================
Last epoch predictions
======================
acc: 0.735072463768116
f1:  0.7964365256124721
confusion matrix
[[374 204]
 [253 894]]
======================
Best epoch predictions
======================
acc: 0.735072463768116
f1:  0.7964365256124721
confusion matrix
[[374 204]
 [253 894]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: False
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

feab is None!
Trainable parameters: 22,842,827
Non-trainable parameters: 0
Total parameters: 22,842,827
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.5634782608695652
0.664886515353805
[[225 353]
 [400 747]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 7s - loss: 5.6291 - acc: 0.6678 - val_loss: 5.1938 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_135235.hdf5
Epoch 2/30
 - 5s - loss: 5.4656 - acc: 0.6712 - val_loss: 5.0704 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 5s - loss: 5.3832 - acc: 0.6712 - val_loss: 5.0177 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 5s - loss: 5.3460 - acc: 0.6712 - val_loss: 4.9924 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 5s - loss: 5.3275 - acc: 0.6712 - val_loss: 4.9793 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 5s - loss: 5.3177 - acc: 0.6712 - val_loss: 4.9720 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 5s - loss: 5.3120 - acc: 0.6712 - val_loss: 4.9678 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 5s - loss: 5.3086 - acc: 0.6712 - val_loss: 4.9651 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 5s - loss: 5.3065 - acc: 0.6712 - val_loss: 4.9633 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 5s - loss: 5.3050 - acc: 0.6712 - val_loss: 4.9621 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 5s - loss: 5.3039 - acc: 0.6712 - val_loss: 4.9612 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 5s - loss: 5.3032 - acc: 0.6712 - val_loss: 4.9606 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 5s - loss: 5.3026 - acc: 0.6712 - val_loss: 4.9601 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 5s - loss: 5.3022 - acc: 0.6712 - val_loss: 4.9597 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 5s - loss: 5.3019 - acc: 0.6712 - val_loss: 4.9594 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 5s - loss: 5.3016 - acc: 0.6712 - val_loss: 4.9592 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 5s - loss: 5.3014 - acc: 0.6712 - val_loss: 4.9590 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 5s - loss: 1.7109 - acc: 0.6368 - val_loss: 0.6489 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 5s - loss: 0.6747 - acc: 0.6454 - val_loss: 0.6386 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 5s - loss: 0.6699 - acc: 0.6638 - val_loss: 0.6592 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 5s - loss: 0.6633 - acc: 0.6709 - val_loss: 0.6366 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 5s - loss: 0.6783 - acc: 0.6604 - val_loss: 0.6739 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 5s - loss: 0.6769 - acc: 0.6494 - val_loss: 0.6414 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 5s - loss: 0.6733 - acc: 0.6626 - val_loss: 0.6501 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 5s - loss: 0.6702 - acc: 0.6712 - val_loss: 0.6473 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 5s - loss: 0.6647 - acc: 0.6712 - val_loss: 0.6493 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 5s - loss: 0.6610 - acc: 0.6712 - val_loss: 0.6649 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 5s - loss: 0.6613 - acc: 0.6712 - val_loss: 0.6551 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00028: val_acc did not improve
Epoch 29/30
 - 5s - loss: 0.6700 - acc: 0.6509 - val_loss: 0.6434 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 5s - loss: 0.6568 - acc: 0.6712 - val_loss: 0.6414 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.664927536231884
f1:  0.7987465181058496
confusion matrix
[[   0  578]
 [   0 1147]]
======================
Best epoch predictions
======================
acc: 0.664927536231884
f1:  0.7987465181058496
confusion matrix
[[   0  578]
 [   0 1147]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 22,790,677
Non-trainable parameters: 0
Total parameters: 22,790,677
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.664927536231884
0.7987465181058496
[[   0  578]
 [   0 1147]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 10s - loss: 5.3924 - acc: 0.6712 - val_loss: 5.0359 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_135538.hdf5
Epoch 2/30
 - 9s - loss: 5.3518 - acc: 0.6712 - val_loss: 4.9902 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 9s - loss: 5.3224 - acc: 0.6712 - val_loss: 4.9724 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 9s - loss: 5.3105 - acc: 0.6712 - val_loss: 4.9650 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 9s - loss: 5.3054 - acc: 0.6712 - val_loss: 4.9617 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 9s - loss: 5.3031 - acc: 0.6712 - val_loss: 4.9601 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 10s - loss: 1.5510 - acc: 0.6340 - val_loss: 0.6568 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 9s - loss: 0.6705 - acc: 0.6586 - val_loss: 0.6544 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 9s - loss: 0.6637 - acc: 0.6748 - val_loss: 0.6422 - val_acc: 0.7047
val_acc: 0.7047
val_f1: 0.8242
val_conf_mat:
[[ 10 241]
 [  0 565]]

Epoch 00009: val_acc improved from 0.69240 to 0.70466, saving model to ../checkpoints/he_mpcnn/cp_20180622_135538.hdf5
Epoch 10/30
 - 9s - loss: 0.6291 - acc: 0.7420 - val_loss: 0.6573 - val_acc: 0.7500
val_acc: 0.7500
val_f1: 0.8381
val_conf_mat:
[[ 84 167]
 [ 37 528]]

Epoch 00010: val_acc improved from 0.70466 to 0.75000, saving model to ../checkpoints/he_mpcnn/cp_20180622_135538.hdf5
Epoch 11/30
 - 9s - loss: 0.5394 - acc: 0.8561 - val_loss: 0.6487 - val_acc: 0.7598
val_acc: 0.7598
val_f1: 0.8228
val_conf_mat:
[[165  86]
 [110 455]]

Epoch 00011: val_acc improved from 0.75000 to 0.75980, saving model to ../checkpoints/he_mpcnn/cp_20180622_135538.hdf5
Epoch 12/30
 - 9s - loss: 0.4505 - acc: 0.8948 - val_loss: 0.6724 - val_acc: 0.7230
val_acc: 0.7230
val_f1: 0.8318
val_conf_mat:
[[ 31 220]
 [  6 559]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 9s - loss: 0.3892 - acc: 0.9383 - val_loss: 0.6765 - val_acc: 0.7757
val_acc: 0.7757
val_f1: 0.8450
val_conf_mat:
[[134 117]
 [ 66 499]]

Epoch 00013: val_acc improved from 0.75980 to 0.77574, saving model to ../checkpoints/he_mpcnn/cp_20180622_135538.hdf5
Epoch 14/30
 - 9s - loss: 0.3092 - acc: 0.9592 - val_loss: 0.7476 - val_acc: 0.7696
val_acc: 0.7696
val_f1: 0.8388
val_conf_mat:
[[139 112]
 [ 76 489]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 9s - loss: 0.2557 - acc: 0.9733 - val_loss: 0.8379 - val_acc: 0.7525
val_acc: 0.7525
val_f1: 0.8150
val_conf_mat:
[[169  82]
 [120 445]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 9s - loss: 0.2132 - acc: 0.9810 - val_loss: 0.8219 - val_acc: 0.7672
val_acc: 0.7672
val_f1: 0.8376
val_conf_mat:
[[136 115]
 [ 75 490]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 9s - loss: 0.1833 - acc: 0.9840 - val_loss: 0.8952 - val_acc: 0.7390
val_acc: 0.7390
val_f1: 0.8022
val_conf_mat:
[[171  80]
 [133 432]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 10s - loss: 0.1678 - acc: 0.9847 - val_loss: 0.7175 - val_acc: 0.7574
val_acc: 0.7574
val_f1: 0.8254
val_conf_mat:
[[150 101]
 [ 97 468]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 9s - loss: 0.1521 - acc: 0.9868 - val_loss: 0.7574 - val_acc: 0.7537
val_acc: 0.7537
val_f1: 0.8181
val_conf_mat:
[[163  88]
 [113 452]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 9s - loss: 0.1360 - acc: 0.9883 - val_loss: 0.7662 - val_acc: 0.7721
val_acc: 0.7721
val_f1: 0.8330
val_conf_mat:
[[166  85]
 [101 464]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 9s - loss: 0.1383 - acc: 0.9865 - val_loss: 0.8480 - val_acc: 0.7598
val_acc: 0.7598
val_f1: 0.8417
val_conf_mat:
[[ 99 152]
 [ 44 521]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 9s - loss: 0.1405 - acc: 0.9896 - val_loss: 1.0373 - val_acc: 0.7145
val_acc: 0.7145
val_f1: 0.7753
val_conf_mat:
[[181  70]
 [163 402]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 9s - loss: 0.1311 - acc: 0.9917 - val_loss: 0.9471 - val_acc: 0.7549
val_acc: 0.7549
val_f1: 0.8249
val_conf_mat:
[[145 106]
 [ 94 471]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 9s - loss: 0.1138 - acc: 0.9942 - val_loss: 1.0763 - val_acc: 0.7426
val_acc: 0.7426
val_f1: 0.8059
val_conf_mat:
[[170  81]
 [129 436]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 9s - loss: 0.1026 - acc: 0.9942 - val_loss: 0.9743 - val_acc: 0.7598
val_acc: 0.7598
val_f1: 0.8256
val_conf_mat:
[[156  95]
 [101 464]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 10s - loss: 0.1027 - acc: 0.9948 - val_loss: 1.0437 - val_acc: 0.7574
val_acc: 0.7574
val_f1: 0.8235
val_conf_mat:
[[156  95]
 [103 462]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 9s - loss: 0.0847 - acc: 0.9957 - val_loss: 1.0946 - val_acc: 0.7574
val_acc: 0.7574
val_f1: 0.8272
val_conf_mat:
[[144 107]
 [ 91 474]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 9s - loss: 0.0744 - acc: 0.9957 - val_loss: 1.1049 - val_acc: 0.7537
val_acc: 0.7537
val_f1: 0.8269
val_conf_mat:
[[135 116]
 [ 85 480]]

Epoch 00028: val_acc did not improve
Epoch 29/30
 - 9s - loss: 0.0674 - acc: 0.9957 - val_loss: 1.0553 - val_acc: 0.7561
val_acc: 0.7561
val_f1: 0.8351
val_conf_mat:
[[113 138]
 [ 61 504]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 9s - loss: 0.0581 - acc: 0.9966 - val_loss: 1.0923 - val_acc: 0.7500
val_acc: 0.7500
val_f1: 0.8268
val_conf_mat:
[[125 126]
 [ 78 487]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.7553623188405797
f1:  0.8283157038242474
confusion matrix
[[ 285  293]
 [ 129 1018]]
======================
Best epoch predictions
======================
acc: 0.7565217391304347
f1:  0.8295454545454546
confusion matrix
[[ 283  295]
 [ 125 1022]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20)]
Pool ops: ['max', 'min']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 19,274,302
Non-trainable parameters: 0
Total parameters: 19,274,302
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.5721739130434783
0.7048
[[106 472]
 [266 881]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 7s - loss: 5.4155 - acc: 0.6693 - val_loss: 5.0399 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_140051.hdf5
Epoch 2/30
 - 6s - loss: 5.3576 - acc: 0.6712 - val_loss: 4.9975 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 6s - loss: 5.3304 - acc: 0.6712 - val_loss: 4.9808 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 6s - loss: 5.3187 - acc: 0.6712 - val_loss: 4.9729 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 6s - loss: 5.3130 - acc: 0.6712 - val_loss: 4.9688 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 6s - loss: 5.3097 - acc: 0.6712 - val_loss: 4.9663 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 6s - loss: 5.3077 - acc: 0.6712 - val_loss: 4.9647 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 6s - loss: 5.3064 - acc: 0.6712 - val_loss: 4.9636 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 6s - loss: 5.3054 - acc: 0.6712 - val_loss: 4.9627 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 6s - loss: 5.3047 - acc: 0.6712 - val_loss: 4.9621 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 6s - loss: 5.3041 - acc: 0.6712 - val_loss: 4.9615 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 6s - loss: 5.3036 - acc: 0.6712 - val_loss: 4.9611 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 6s - loss: 5.3032 - acc: 0.6712 - val_loss: 4.9607 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 6s - loss: 5.3029 - acc: 0.6712 - val_loss: 4.9604 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 6s - loss: 5.3026 - acc: 0.6712 - val_loss: 4.9602 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 6s - loss: 5.3023 - acc: 0.6712 - val_loss: 4.9599 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 6s - loss: 5.3021 - acc: 0.6712 - val_loss: 4.9597 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 6s - loss: 5.3019 - acc: 0.6712 - val_loss: 4.9595 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 6s - loss: 5.3017 - acc: 0.6712 - val_loss: 4.9594 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 6s - loss: 5.3016 - acc: 0.6712 - val_loss: 4.9592 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 6s - loss: 5.3014 - acc: 0.6712 - val_loss: 4.9591 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 6s - loss: 5.3013 - acc: 0.6712 - val_loss: 4.9590 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 6s - loss: 5.1280 - acc: 0.6669 - val_loss: 1.2919 - val_acc: 0.3076
val_acc: 0.3076
val_f1: 0.0000
val_conf_mat:
[[251   0]
 [565   0]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 6s - loss: 0.7077 - acc: 0.6482 - val_loss: 0.6392 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 6s - loss: 0.6528 - acc: 0.6794 - val_loss: 0.6048 - val_acc: 0.7500
val_acc: 0.7500
val_f1: 0.8373
val_conf_mat:
[[ 87 164]
 [ 40 525]]

Epoch 00025: val_acc improved from 0.69240 to 0.75000, saving model to ../checkpoints/he_mpcnn/cp_20180622_140051.hdf5
Epoch 26/30
 - 6s - loss: 0.5438 - acc: 0.8215 - val_loss: 0.6741 - val_acc: 0.7047
val_acc: 0.7047
val_f1: 0.8242
val_conf_mat:
[[ 10 241]
 [  0 565]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 6s - loss: 0.3820 - acc: 0.9270 - val_loss: 0.7400 - val_acc: 0.7426
val_acc: 0.7426
val_f1: 0.8041
val_conf_mat:
[[175  76]
 [134 431]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 6s - loss: 0.2537 - acc: 0.9653 - val_loss: 0.6925 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8332
val_conf_mat:
[[134 117]
 [ 78 487]]

Epoch 00028: val_acc improved from 0.75000 to 0.76103, saving model to ../checkpoints/he_mpcnn/cp_20180622_140051.hdf5
Epoch 29/30
 - 6s - loss: 0.1897 - acc: 0.9844 - val_loss: 0.7328 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8411
val_conf_mat:
[[105 146]
 [ 49 516]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 6s - loss: 0.1472 - acc: 0.9926 - val_loss: 0.9061 - val_acc: 0.7574
val_acc: 0.7574
val_f1: 0.8238
val_conf_mat:
[[155  96]
 [102 463]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.7373913043478261
f1:  0.8069876438005965
confusion matrix
[[325 253]
 [200 947]]
======================
Best epoch predictions
======================
acc: 0.7507246376811594
f1:  0.8253452477660439
confusion matrix
[[ 279  299]
 [ 131 1016]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: True   Algorithm 2: True
Algorithm 1
-----------
Cosine similarity: False
Euclidean distance: False
Absolute difference: True

Algorithm 2
-----------
Cosine similarity: False
Euclidean distance: False
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 39,545,327
Non-trainable parameters: 0
Total parameters: 39,545,327
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.37971014492753624
0.2357142857142857
[[490  88]
 [982 165]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 20s - loss: 5.6547 - acc: 0.6650 - val_loss: 5.1722 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_140425.hdf5
Epoch 2/30
 - 19s - loss: 5.4441 - acc: 0.6712 - val_loss: 5.0515 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 19s - loss: 5.3683 - acc: 0.6712 - val_loss: 5.0067 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 19s - loss: 5.3381 - acc: 0.6712 - val_loss: 4.9872 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 19s - loss: 5.3242 - acc: 0.6712 - val_loss: 4.9776 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 19s - loss: 5.3170 - acc: 0.6712 - val_loss: 4.9722 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 19s - loss: 5.3127 - acc: 0.6712 - val_loss: 4.9689 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 19s - loss: 5.3100 - acc: 0.6712 - val_loss: 4.9666 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 19s - loss: 5.3080 - acc: 0.6712 - val_loss: 4.9649 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 19s - loss: 5.3065 - acc: 0.6712 - val_loss: 4.9636 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 19s - loss: 5.3054 - acc: 0.6712 - val_loss: 4.9626 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 19s - loss: 5.3045 - acc: 0.6712 - val_loss: 4.9618 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 19s - loss: 5.3038 - acc: 0.6712 - val_loss: 4.9611 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 19s - loss: 5.3032 - acc: 0.6712 - val_loss: 4.9606 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 19s - loss: 5.3027 - acc: 0.6712 - val_loss: 4.9601 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 19s - loss: 1.5987 - acc: 0.6288 - val_loss: 0.6461 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 19s - loss: 0.6780 - acc: 0.6709 - val_loss: 0.6654 - val_acc: 0.7034
val_acc: 0.7034
val_f1: 0.8234
val_conf_mat:
[[ 10 241]
 [  1 564]]

Epoch 00017: val_acc improved from 0.69240 to 0.70343, saving model to ../checkpoints/he_mpcnn/cp_20180622_140425.hdf5
Epoch 18/30
 - 19s - loss: 0.6775 - acc: 0.7405 - val_loss: 0.7923 - val_acc: 0.7047
val_acc: 0.7047
val_f1: 0.8240
val_conf_mat:
[[ 11 240]
 [  1 564]]

Epoch 00018: val_acc improved from 0.70343 to 0.70466, saving model to ../checkpoints/he_mpcnn/cp_20180622_140425.hdf5
Epoch 19/30
 - 19s - loss: 0.6136 - acc: 0.8650 - val_loss: 0.8242 - val_acc: 0.6152
val_acc: 0.6152
val_f1: 0.6349
val_conf_mat:
[[229  22]
 [292 273]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 19s - loss: 0.5386 - acc: 0.9206 - val_loss: 0.7147 - val_acc: 0.7475
val_acc: 0.7475
val_f1: 0.8107
val_conf_mat:
[[169  82]
 [124 441]]

Epoch 00020: val_acc improved from 0.70466 to 0.74755, saving model to ../checkpoints/he_mpcnn/cp_20180622_140425.hdf5
Epoch 21/30
 - 19s - loss: 0.3967 - acc: 0.9549 - val_loss: 0.7589 - val_acc: 0.7463
val_acc: 0.7463
val_f1: 0.8064
val_conf_mat:
[[178  73]
 [134 431]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 19s - loss: 0.3110 - acc: 0.9758 - val_loss: 0.7317 - val_acc: 0.7635
val_acc: 0.7635
val_f1: 0.8380
val_conf_mat:
[[124 127]
 [ 66 499]]

Epoch 00022: val_acc improved from 0.74755 to 0.76348, saving model to ../checkpoints/he_mpcnn/cp_20180622_140425.hdf5
Epoch 23/30
 - 19s - loss: 0.2298 - acc: 0.9868 - val_loss: 0.8465 - val_acc: 0.7451
val_acc: 0.7451
val_f1: 0.8106
val_conf_mat:
[[163  88]
 [120 445]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 19s - loss: 0.1829 - acc: 0.9929 - val_loss: 0.8853 - val_acc: 0.7623
val_acc: 0.7623
val_f1: 0.8243
val_conf_mat:
[[167  84]
 [110 455]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 19s - loss: 0.1275 - acc: 0.9966 - val_loss: 0.9473 - val_acc: 0.7181
val_acc: 0.7181
val_f1: 0.7736
val_conf_mat:
[[193  58]
 [172 393]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 19s - loss: 0.1209 - acc: 0.9957 - val_loss: 0.7090 - val_acc: 0.7353
val_acc: 0.7353
val_f1: 0.7943
val_conf_mat:
[[183  68]
 [148 417]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 19s - loss: 0.1133 - acc: 0.9963 - val_loss: 0.8950 - val_acc: 0.7426
val_acc: 0.7426
val_f1: 0.8015
val_conf_mat:
[[182  69]
 [141 424]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 19s - loss: 0.0770 - acc: 0.9985 - val_loss: 1.0147 - val_acc: 0.7157
val_acc: 0.7157
val_f1: 0.7730
val_conf_mat:
[[189  62]
 [170 395]]

Epoch 00028: val_acc did not improve
Epoch 29/30
 - 19s - loss: 0.0584 - acc: 0.9988 - val_loss: 1.1851 - val_acc: 0.7353
val_acc: 0.7353
val_f1: 0.7958
val_conf_mat:
[[179  72]
 [144 421]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 19s - loss: 0.0570 - acc: 0.9985 - val_loss: 0.8597 - val_acc: 0.7635
val_acc: 0.7635
val_f1: 0.8281
val_conf_mat:
[[158  93]
 [100 465]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.743768115942029
f1:  0.8104631217838765
confusion matrix
[[338 240]
 [202 945]]
======================
Best epoch predictions
======================
acc: 0.7542028985507246
f1:  0.8297188755020081
confusion matrix
[[ 268  310]
 [ 114 1033]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: False   Algorithm 2: True
Algorithm 2
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: True

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 38,054,327
Non-trainable parameters: 0
Total parameters: 38,054,327
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.35304347826086957
0.11146496815286623
[[ 539   39]
 [1077   70]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 21s - loss: 5.5981 - acc: 0.6678 - val_loss: 5.1428 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 2/30
 - 19s - loss: 5.4203 - acc: 0.6712 - val_loss: 5.0329 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 19s - loss: 5.3533 - acc: 0.6712 - val_loss: 4.9946 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 19s - loss: 5.3280 - acc: 0.6712 - val_loss: 4.9788 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 19s - loss: 5.3170 - acc: 0.6712 - val_loss: 4.9713 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 19s - loss: 5.3114 - acc: 0.6712 - val_loss: 4.9673 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 19s - loss: 5.3082 - acc: 0.6712 - val_loss: 4.9648 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 19s - loss: 5.3062 - acc: 0.6712 - val_loss: 4.9632 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 19s - loss: 5.3049 - acc: 0.6712 - val_loss: 4.9620 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 19s - loss: 5.3039 - acc: 0.6712 - val_loss: 4.9612 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 19s - loss: 5.3031 - acc: 0.6712 - val_loss: 4.9605 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 19s - loss: 5.3025 - acc: 0.6712 - val_loss: 4.9600 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 19s - loss: 5.3021 - acc: 0.6712 - val_loss: 4.9596 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 19s - loss: 5.3017 - acc: 0.6712 - val_loss: 4.9593 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 19s - loss: 5.3014 - acc: 0.6712 - val_loss: 4.9590 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 19s - loss: 5.3012 - acc: 0.6712 - val_loss: 4.9588 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 19s - loss: 3.7282 - acc: 0.6620 - val_loss: 0.6825 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 19s - loss: 0.6898 - acc: 0.6632 - val_loss: 0.6514 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 19s - loss: 0.7007 - acc: 0.6696 - val_loss: 0.7307 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 19s - loss: 0.6721 - acc: 0.6911 - val_loss: 0.6835 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 19s - loss: 0.6420 - acc: 0.8028 - val_loss: 0.7312 - val_acc: 0.7279
val_acc: 0.7279
val_f1: 0.8341
val_conf_mat:
[[ 36 215]
 [  7 558]]

Epoch 00021: val_acc improved from 0.69240 to 0.72794, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 22/30
 - 19s - loss: 0.5257 - acc: 0.8972 - val_loss: 0.7210 - val_acc: 0.7537
val_acc: 0.7537
val_f1: 0.8424
val_conf_mat:
[[ 78 173]
 [ 28 537]]

Epoch 00022: val_acc improved from 0.72794 to 0.75368, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 23/30
 - 19s - loss: 0.4434 - acc: 0.9132 - val_loss: 0.7516 - val_acc: 0.7586
val_acc: 0.7586
val_f1: 0.8407
val_conf_mat:
[[ 99 152]
 [ 45 520]]

Epoch 00023: val_acc improved from 0.75368 to 0.75858, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 24/30
 - 19s - loss: 0.3821 - acc: 0.9482 - val_loss: 0.7082 - val_acc: 0.7659
val_acc: 0.7659
val_f1: 0.8314
val_conf_mat:
[[154  97]
 [ 94 471]]

Epoch 00024: val_acc improved from 0.75858 to 0.76593, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 25/30
 - 19s - loss: 0.3045 - acc: 0.9607 - val_loss: 0.7149 - val_acc: 0.7623
val_acc: 0.7623
val_f1: 0.8446
val_conf_mat:
[[ 95 156]
 [ 38 527]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 19s - loss: 0.2721 - acc: 0.9727 - val_loss: 0.7410 - val_acc: 0.7647
val_acc: 0.7647
val_f1: 0.8408
val_conf_mat:
[[117 134]
 [ 58 507]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 19s - loss: 0.2186 - acc: 0.9853 - val_loss: 0.8347 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8384
val_conf_mat:
[[115 136]
 [ 59 506]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 19s - loss: 0.1764 - acc: 0.9865 - val_loss: 0.6438 - val_acc: 0.7672
val_acc: 0.7672
val_f1: 0.8379
val_conf_mat:
[[135 116]
 [ 74 491]]

Epoch 00028: val_acc improved from 0.76593 to 0.76716, saving model to ../checkpoints/he_mpcnn/cp_20180622_141452.hdf5
Epoch 29/30
 - 19s - loss: 0.1750 - acc: 0.9883 - val_loss: 0.9127 - val_acc: 0.7377
val_acc: 0.7377
val_f1: 0.7922
val_conf_mat:
[[194  57]
 [157 408]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 19s - loss: 0.1643 - acc: 0.9926 - val_loss: 0.9547 - val_acc: 0.7439
val_acc: 0.7439
val_f1: 0.8019
val_conf_mat:
[[184  67]
 [142 423]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.7275362318840579
f1:  0.7830101569713759
confusion matrix
[[407 171]
 [299 848]]
======================
Best epoch predictions
======================
acc: 0.7530434782608696
f1:  0.8242574257425743
confusion matrix
[[300 278]
 [148 999]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: False
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Algorithm 1: True   Algorithm 2: False
Algorithm 1
-----------
Cosine similarity: True
Euclidean distance: True
Absolute difference: False

Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 16,518,827
Non-trainable parameters: 0
Total parameters: 16,518,827
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.49043478260869566
0.6098535286284954
[[159 419]
 [460 687]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 5s - loss: 5.5572 - acc: 0.6690 - val_loss: 5.1025 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_142530.hdf5
Epoch 2/30
 - 4s - loss: 5.3966 - acc: 0.6712 - val_loss: 5.0221 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 4s - loss: 5.3493 - acc: 0.6712 - val_loss: 4.9957 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 4s - loss: 5.3317 - acc: 0.6712 - val_loss: 4.9843 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 4s - loss: 5.3233 - acc: 0.6712 - val_loss: 4.9782 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 5s - loss: 5.3185 - acc: 0.6712 - val_loss: 4.9745 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 5s - loss: 5.3154 - acc: 0.6712 - val_loss: 4.9719 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 5s - loss: 5.3131 - acc: 0.6712 - val_loss: 4.9699 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 5s - loss: 5.3114 - acc: 0.6712 - val_loss: 4.9683 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 5s - loss: 5.3099 - acc: 0.6712 - val_loss: 4.9670 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 5s - loss: 5.3087 - acc: 0.6712 - val_loss: 4.9659 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 5s - loss: 5.3077 - acc: 0.6712 - val_loss: 4.9650 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 5s - loss: 5.3068 - acc: 0.6712 - val_loss: 4.9641 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 5s - loss: 5.3060 - acc: 0.6712 - val_loss: 4.9634 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 5s - loss: 5.3054 - acc: 0.6712 - val_loss: 4.9628 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 5s - loss: 5.3048 - acc: 0.6712 - val_loss: 4.9622 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00016: val_acc did not improve
Epoch 17/30
 - 5s - loss: 5.3042 - acc: 0.6712 - val_loss: 4.9617 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 5s - loss: 2.3739 - acc: 0.6485 - val_loss: 0.6447 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 5s - loss: 0.7178 - acc: 0.6933 - val_loss: 0.8124 - val_acc: 0.6936
val_acc: 0.6936
val_f1: 0.7357
val_conf_mat:
[[218  33]
 [217 348]]

Epoch 00019: val_acc improved from 0.69240 to 0.69363, saving model to ../checkpoints/he_mpcnn/cp_20180622_142530.hdf5
Epoch 20/30
 - 4s - loss: 0.6578 - acc: 0.8132 - val_loss: 0.7738 - val_acc: 0.7377
val_acc: 0.7377
val_f1: 0.7977
val_conf_mat:
[[180  71]
 [143 422]]

Epoch 00020: val_acc improved from 0.69363 to 0.73775, saving model to ../checkpoints/he_mpcnn/cp_20180622_142530.hdf5
Epoch 21/30
 - 5s - loss: 0.5093 - acc: 0.9230 - val_loss: 0.8937 - val_acc: 0.7574
val_acc: 0.7574
val_f1: 0.8219
val_conf_mat:
[[161  90]
 [108 457]]

Epoch 00021: val_acc improved from 0.73775 to 0.75735, saving model to ../checkpoints/he_mpcnn/cp_20180622_142530.hdf5
Epoch 22/30
 - 5s - loss: 0.3830 - acc: 0.9690 - val_loss: 0.8153 - val_acc: 0.7647
val_acc: 0.7647
val_f1: 0.8387
val_conf_mat:
[[125 126]
 [ 66 499]]

Epoch 00022: val_acc improved from 0.75735 to 0.76471, saving model to ../checkpoints/he_mpcnn/cp_20180622_142530.hdf5
Epoch 23/30
 - 5s - loss: 0.2942 - acc: 0.9840 - val_loss: 0.9310 - val_acc: 0.7610
val_acc: 0.7610
val_f1: 0.8363
val_conf_mat:
[[123 128]
 [ 67 498]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 5s - loss: 0.2404 - acc: 0.9914 - val_loss: 1.1449 - val_acc: 0.7451
val_acc: 0.7451
val_f1: 0.8243
val_conf_mat:
[[120 131]
 [ 77 488]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 5s - loss: 0.1917 - acc: 0.9945 - val_loss: 1.0087 - val_acc: 0.7451
val_acc: 0.7451
val_f1: 0.8153
val_conf_mat:
[[149 102]
 [106 459]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 5s - loss: 0.1669 - acc: 0.9948 - val_loss: 1.0167 - val_acc: 0.7475
val_acc: 0.7475
val_f1: 0.8202
val_conf_mat:
[[140 111]
 [ 95 470]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 5s - loss: 0.1431 - acc: 0.9966 - val_loss: 1.0914 - val_acc: 0.7549
val_acc: 0.7549
val_f1: 0.8319
val_conf_mat:
[[121 130]
 [ 70 495]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 5s - loss: 0.1243 - acc: 0.9979 - val_loss: 1.0636 - val_acc: 0.7500
val_acc: 0.7500
val_f1: 0.8247
val_conf_mat:
[[132 119]
 [ 85 480]]

Epoch 00028: val_acc did not improve
Epoch 29/30
 - 5s - loss: 0.1104 - acc: 0.9985 - val_loss: 1.1428 - val_acc: 0.7512
val_acc: 0.7512
val_f1: 0.8242
val_conf_mat:
[[137 114]
 [ 89 476]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 5s - loss: 0.0856 - acc: 0.9985 - val_loss: 1.0345 - val_acc: 0.7561
val_acc: 0.7561
val_f1: 0.8283
val_conf_mat:
[[137 114]
 [ 85 480]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.7553623188405797
f1:  0.8250414593698177
confusion matrix
[[308 270]
 [152 995]]
======================
Best epoch predictions
======================
acc: 0.7669565217391304
f1:  0.8377723970944311
confusion matrix
[[ 285  293]
 [ 109 1038]]
DONE


==============
PROGRAM STARTS
==============
=======================
Loading embedding files
=======================
loading ... msrpc_POSkimprep_nolower_glove_embcap_20180611.pickle
Embeddings shape (pretrained GloVe): (20504, 300)  unknown tokens: 488
loading ... msrpc_POSkimprep_nolower_POSword2vec_embcap_20180611.pickle
Embeddings shape (pretrained POS word2vec): (20504, 200)  unknown tokens: 1533
loading ... msrpc_POSkimprep_nolower_paragram25_embcap_20180611.pickle
Embeddings shape (pretrained PARAGRAM): (20504, 25)  unknown tokens: 1868
Final embeddings dim: 525


===================
Generating datasets
===================
Max seq length: 39
X_train: (4076, 39)
Y_train: (4076,)
X_test: (1725, 39)
Y_test: (1725,)


================
Generating model
================
Convolution activation: tanh
Dense activation: tanh
Group A: True   Group B: True
Group A config
--------------
Filters: [(1, 525), (2, 525), (3, 525), (None, 525)]
Pool ops: ['max', 'min', 'mean']

Group B config
--------------
Using DepthwiseConv2D
Filters: [(1, 20), (2, 20), (3, 20)]
Pool ops: ['max', 'min']

Algorithm 1: False   Algorithm 2: False
Other settings
--------------
MLP hidden units: 250
Regularization: 0.0001
Trainable embeddings: True

Trainable parameters: 50,570,327
Non-trainable parameters: 0
Total parameters: 50,570,327
Done!


===============
Compiling model
===============
Optimizer: adam
Learning rate: 0.001
Loss: categorical_crossentropy
Done!


==================
Training model ...
==================
Epochs: 30
Batch size: 32
Forward propagation with random values
0.5089855072463768
0.5902273826802128
[[268 310]
 [537 610]]
Train on 3260 samples, validate on 816 samples
Epoch 1/30
 - 22s - loss: 5.5904 - acc: 0.6681 - val_loss: 5.1120 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00001: val_acc improved from -inf to 0.69240, saving model to ../checkpoints/he_mpcnn/cp_20180622_142808.hdf5
Epoch 2/30
 - 20s - loss: 5.3987 - acc: 0.6712 - val_loss: 5.0195 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00002: val_acc did not improve
Epoch 3/30
 - 20s - loss: 5.3447 - acc: 0.6712 - val_loss: 4.9895 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00003: val_acc did not improve
Epoch 4/30
 - 20s - loss: 5.3246 - acc: 0.6712 - val_loss: 4.9767 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00004: val_acc did not improve
Epoch 5/30
 - 20s - loss: 5.3155 - acc: 0.6712 - val_loss: 4.9703 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00005: val_acc did not improve
Epoch 6/30
 - 20s - loss: 5.3107 - acc: 0.6712 - val_loss: 4.9668 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00006: val_acc did not improve
Epoch 7/30
 - 20s - loss: 5.3080 - acc: 0.6712 - val_loss: 4.9648 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00007: val_acc did not improve
Epoch 8/30
 - 20s - loss: 5.3063 - acc: 0.6712 - val_loss: 4.9634 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00008: val_acc did not improve
Epoch 9/30
 - 20s - loss: 5.3052 - acc: 0.6712 - val_loss: 4.9625 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00009: val_acc did not improve
Epoch 10/30
 - 20s - loss: 5.3044 - acc: 0.6712 - val_loss: 4.9618 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00010: val_acc did not improve
Epoch 11/30
 - 20s - loss: 5.3038 - acc: 0.6712 - val_loss: 4.9612 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00011: val_acc did not improve
Epoch 12/30
 - 20s - loss: 5.3033 - acc: 0.6712 - val_loss: 4.9608 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00012: val_acc did not improve
Epoch 13/30
 - 20s - loss: 3.6181 - acc: 0.6604 - val_loss: 0.8632 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00013: val_acc did not improve
Epoch 14/30
 - 20s - loss: 0.7505 - acc: 0.6399 - val_loss: 0.6729 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00014: val_acc did not improve
Epoch 15/30
 - 20s - loss: 0.6773 - acc: 0.6712 - val_loss: 0.6613 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00015: val_acc did not improve
Epoch 16/30
 - 20s - loss: 0.6731 - acc: 0.6709 - val_loss: 0.6865 - val_acc: 0.6936
val_acc: 0.6936
val_f1: 0.8186
val_conf_mat:
[[  2 249]
 [  1 564]]

Epoch 00016: val_acc improved from 0.69240 to 0.69363, saving model to ../checkpoints/he_mpcnn/cp_20180622_142808.hdf5
Epoch 17/30
 - 20s - loss: 0.6816 - acc: 0.6718 - val_loss: 0.6568 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00017: val_acc did not improve
Epoch 18/30
 - 20s - loss: 0.6739 - acc: 0.6712 - val_loss: 0.6408 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00018: val_acc did not improve
Epoch 19/30
 - 20s - loss: 0.6720 - acc: 0.6712 - val_loss: 0.6650 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00019: val_acc did not improve
Epoch 20/30
 - 20s - loss: 0.6665 - acc: 0.6712 - val_loss: 0.6767 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00020: val_acc did not improve
Epoch 21/30
 - 20s - loss: 0.6740 - acc: 0.6712 - val_loss: 0.6397 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00021: val_acc did not improve
Epoch 22/30
 - 20s - loss: 0.6697 - acc: 0.6715 - val_loss: 0.6652 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00022: val_acc did not improve
Epoch 23/30
 - 20s - loss: 0.6725 - acc: 0.6712 - val_loss: 0.6429 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00023: val_acc did not improve
Epoch 24/30
 - 20s - loss: 0.6616 - acc: 0.6712 - val_loss: 0.6483 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00024: val_acc did not improve
Epoch 25/30
 - 20s - loss: 0.6693 - acc: 0.6712 - val_loss: 0.6356 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00025: val_acc did not improve
Epoch 26/30
 - 20s - loss: 0.6714 - acc: 0.6712 - val_loss: 0.6482 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00026: val_acc did not improve
Epoch 27/30
 - 20s - loss: 0.6713 - acc: 0.6712 - val_loss: 0.6579 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00027: val_acc did not improve
Epoch 28/30
 - 20s - loss: 0.6978 - acc: 0.6706 - val_loss: 0.6596 - val_acc: 0.6924
val_acc: 0.6924
val_f1: 0.8182
val_conf_mat:
[[  0 251]
 [  0 565]]

Epoch 00028: val_acc did not improve
Epoch 29/30
 - 20s - loss: 0.6769 - acc: 0.6736 - val_loss: 0.6571 - val_acc: 0.6912
val_acc: 0.6912
val_f1: 0.8031
val_conf_mat:
[[ 50 201]
 [ 51 514]]

Epoch 00029: val_acc did not improve
Epoch 30/30
 - 20s - loss: 0.6084 - acc: 0.7788 - val_loss: 0.8058 - val_acc: 0.6887
val_acc: 0.6887
val_f1: 0.7880
val_conf_mat:
[[ 90 161]
 [ 93 472]]

Epoch 00030: val_acc did not improve
Done!


======================
Last epoch predictions
======================
acc: 0.6776811594202898
f1:  0.7750809061488673
confusion matrix
[[211 367]
 [189 958]]
======================
Best epoch predictions
======================
acc: 0.6655072463768116
f1:  0.7987443320544122
confusion matrix
[[   3  575]
 [   2 1145]]
DONE


